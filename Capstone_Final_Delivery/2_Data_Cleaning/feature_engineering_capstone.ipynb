{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a223ea81-9793-4381-951e-bb6ceef84c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae3762-216e-42e2-91fb-b90c29f2402c",
   "metadata": {},
   "source": [
    "We are interested in how to predict or find a \"good\" journal, indicated by the impact factor (IF), with various criteria.\n",
    "In this case we perticularlly want to know if the name containing certain keywords makes a difference among all other criteria.\n",
    "Although IF is calculated by the ariticle citation, it has its time limit and can undermise good journal that talks about less hot fields.\n",
    "Hence we do also want to see if a good journal remains good, or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52c948e6-2699-47c0-bad7-ffe99045cdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2072 entries, 0 to 2071\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   jornal_url       2072 non-null   object \n",
      " 1   journal          2072 non-null   object \n",
      " 2   article_number   2072 non-null   float64\n",
      " 3   citation_number  2072 non-null   float64\n",
      " 4   impact_factor    2072 non-null   float64\n",
      " 5   most_cited       2072 non-null   object \n",
      " 6   year             2072 non-null   float64\n",
      " 7   cited_by         2072 non-null   float64\n",
      " 8   Search_Keywords  2072 non-null   object \n",
      " 9   Keyword_1        2072 non-null   object \n",
      " 10  Keyword_2        2072 non-null   object \n",
      "dtypes: float64(5), object(6)\n",
      "memory usage: 178.2+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv('cleaned_impact_factor_merged_file.csv')\n",
    "\n",
    "# Clean 'Keyword_1' column\n",
    "df['Keyword_1'] = df['Keyword_1'].astype(str)  # Convert to string\n",
    "df['Keyword_1'] = df['Keyword_1'].str.strip()  # Remove leading and trailing whitespaces\n",
    "df['Keyword_1'] = df['Keyword_1'].replace('', np.nan)  # Replace empty strings with NaN\n",
    "\n",
    "# Clean 'Keyword_2' column\n",
    "df['Keyword_2'] = df['Keyword_2'].astype(str)  # Convert to string\n",
    "df['Keyword_2'] = df['Keyword_2'].str.strip()  # Remove leading and trailing whitespaces\n",
    "df['Keyword_2'] = df['Keyword_2'].replace('', np.nan)  # Replace empty strings with NaN\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a81ad46-354f-41e1-aec8-e362455686fe",
   "metadata": {},
   "source": [
    "Converting the keyword information into categorical values that we really is interested about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df1c64dd-6008-48e3-bd56-f735ba36185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic_in_journal'] = df['journal'].str.contains('|'.join(df['Keyword_1']), case=False)\n",
    "df['specifier_in_journal'] = df['journal'].str.contains('|'.join(df['Keyword_2']), case=False)\n",
    "\n",
    "df['topic_in_most_cited'] = df['most_cited'].str.contains('|'.join(df['Keyword_1']), case=False)\n",
    "df['specifier_in_most_cited'] = df['most_cited'].str.contains('|'.join(df['Keyword_1']), case=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa58e784-537f-4700-bae3-5bf25a864c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2072 entries, 0 to 2071\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   jornal_url               2072 non-null   object \n",
      " 1   journal                  2072 non-null   object \n",
      " 2   article_number           2072 non-null   float64\n",
      " 3   citation_number          2072 non-null   float64\n",
      " 4   impact_factor            2072 non-null   float64\n",
      " 5   most_cited               2072 non-null   object \n",
      " 6   year                     2072 non-null   float64\n",
      " 7   cited_by                 2072 non-null   float64\n",
      " 8   Search_Keywords          2072 non-null   object \n",
      " 9   Keyword_1                2072 non-null   object \n",
      " 10  Keyword_2                2072 non-null   object \n",
      " 11  topic_in_journal         2072 non-null   bool   \n",
      " 12  specifier_in_journal     2072 non-null   bool   \n",
      " 13  topic_in_most_cited      2072 non-null   bool   \n",
      " 14  specifier_in_most_cited  2072 non-null   bool   \n",
      "dtypes: bool(4), float64(5), object(6)\n",
      "memory usage: 186.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_bk = df.copy()\n",
    "df_bk.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31a7145-2265-48ca-8efe-801cc22961f9",
   "metadata": {},
   "source": [
    "By converting the search keywords, what we really want to know is if the keyword appears in the journal name and in its mosts cited article.\n",
    "The keyword 1 is the topic we are interested in, in this case, cancer. And the second is for the more specific field, nano for example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f60b33d6-1610-4040-a55b-6b1f7ddc448e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2072 entries, 0 to 2071\n",
      "Data columns (total 18 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   jornal_url                     2072 non-null   object \n",
      " 1   journal                        2072 non-null   object \n",
      " 2   article_number                 2072 non-null   float64\n",
      " 3   citation_number                2072 non-null   float64\n",
      " 4   impact_factor                  2072 non-null   float64\n",
      " 5   most_cited                     2072 non-null   object \n",
      " 6   year                           2072 non-null   float64\n",
      " 7   cited_by                       2072 non-null   float64\n",
      " 8   Search_Keywords                2072 non-null   object \n",
      " 9   Keyword_1                      2072 non-null   object \n",
      " 10  Keyword_2                      2072 non-null   object \n",
      " 11  topic_in_journal_True          2072 non-null   uint8  \n",
      " 12  specifier_in_journal_False     2072 non-null   uint8  \n",
      " 13  specifier_in_journal_True      2072 non-null   uint8  \n",
      " 14  topic_in_most_cited_False      2072 non-null   uint8  \n",
      " 15  topic_in_most_cited_True       2072 non-null   uint8  \n",
      " 16  specifier_in_most_cited_False  2072 non-null   uint8  \n",
      " 17  specifier_in_most_cited_True   2072 non-null   uint8  \n",
      "dtypes: float64(5), object(6), uint8(7)\n",
      "memory usage: 192.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Select the categorical columns to create dummy variables\n",
    "categorical_columns = ['topic_in_journal', 'specifier_in_journal', 'topic_in_most_cited', 'specifier_in_most_cited']\n",
    "\n",
    "# Create dummy variables for the categorical columns\n",
    "dummy_df = pd.get_dummies(df, columns=categorical_columns)\n",
    "\n",
    "# Print the dummy dataset\n",
    "dummy_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f8c46e-0edb-448b-85fd-200419249da7",
   "metadata": {},
   "source": [
    "Since all journal has the tpoic (topic in journal only has true), we will drop it among other names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1771cec8-3ce2-4c4e-be84-4dcb1fabb424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2072 entries, 0 to 2071\n",
      "Data columns (total 11 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   article_number                 2072 non-null   float64\n",
      " 1   citation_number                2072 non-null   float64\n",
      " 2   impact_factor                  2072 non-null   float64\n",
      " 3   year                           2072 non-null   float64\n",
      " 4   cited_by                       2072 non-null   float64\n",
      " 5   specifier_in_journal_False     2072 non-null   uint8  \n",
      " 6   specifier_in_journal_True      2072 non-null   uint8  \n",
      " 7   topic_in_most_cited_False      2072 non-null   uint8  \n",
      " 8   topic_in_most_cited_True       2072 non-null   uint8  \n",
      " 9   specifier_in_most_cited_False  2072 non-null   uint8  \n",
      " 10  specifier_in_most_cited_True   2072 non-null   uint8  \n",
      "dtypes: float64(5), uint8(6)\n",
      "memory usage: 93.2 KB\n"
     ]
    }
   ],
   "source": [
    "# Drop object columns from the DataFrame\n",
    "df_dropped = dummy_df.drop(['topic_in_journal_True'], axis=1)\n",
    "df_dropped = df_dropped.drop(df_dropped.select_dtypes(include=['object']), axis=1)\n",
    "df_dropped.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051ca84f-9595-4730-addf-a49c5b4a126b",
   "metadata": {},
   "source": [
    "We want to fit for impact factor, hence target is impact factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2c2f9bc-1a67-40ab-b2bf-9c1783271fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1657, 10)\n",
      "Testing set shape: (415, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_dropped.drop('impact_factor', axis=1), df_dropped['impact_factor'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting subsets\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d8084f-7dff-4829-a1f9-5fb89c15899e",
   "metadata": {},
   "source": [
    "Scale the dataset basing on training set, and this scaler will be applied to testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f95c9767-c0f0-455f-ba08-59d3be64b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training set and scale it\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Scale the testing set using the fitted scaler\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00e5c328-100d-4086-b88b-c88af281f365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58d9d39f-1911-48f0-9986-461e0c7eaeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_list={'df' : df_dropped,\n",
    "             'X_train' : X_train,\n",
    "             'X_test' : X_test,\n",
    "             'y_train': y_train,\n",
    "             'y_test': y_test,\n",
    "             'scaler' : scaler,\n",
    "             'X_train_scaled': X_train_scaled,\n",
    "             'X_test_scaled': X_test_scaled\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c177ba4-be22-4191-bd54-b13293f88e4b",
   "metadata": {},
   "source": [
    "Save data for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af6afe83-0786-4313-a56c-824c0539a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed_datamaster_list.pkl', 'wb') as file:\n",
    "    pickle.dump(master_list, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
